{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "673"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from project_config import PREPROCESSED_2012_DATA_FILE, PREPROCESSED_2022_DATA_FILE\n",
    "from utils.file_encoding_detector import detect_encoding\n",
    "from utils.read_csv_file import read_csv_file\n",
    "\n",
    "file_2012 = PREPROCESSED_2012_DATA_FILE\n",
    "file_2022 = PREPROCESSED_2022_DATA_FILE\n",
    "\n",
    "df_1 = read_csv_file(file_2012)\n",
    "df_2 = read_csv_file(file_2022)\n",
    "\n",
    "df_2.group.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_config import YEARBOOK_2012_DATA_DIR\n",
    "\n",
    "\n",
    "source_data_dir = YEARBOOK_2012_DATA_DIR\n",
    "\n",
    "files_to_check_against = list(source_data_dir.glob(\"*.xls*\"))\n",
    "\n",
    "print(files_to_check_against)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17403 98742\n"
     ]
    }
   ],
   "source": [
    "from project_config import TRAINING_DATA_FILE, TRAINING_INFERENCE_DATA_FILE\n",
    "from utils.read_csv_file import read_csv_file\n",
    "\n",
    "df1 = read_csv_file(TRAINING_DATA_FILE)\n",
    "df2 = read_csv_file(TRAINING_INFERENCE_DATA_FILE)\n",
    "\n",
    "print(len(df1), len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load pre-trained Word2Vec model (Google News dataset)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(\n",
    "    \"GoogleNews-vectors-negative300.bin\", binary=True\n",
    ")\n",
    "\n",
    "# Words to visualize\n",
    "words = [\"king\", \"queen\", \"man\", \"woman\"]\n",
    "vectors = [word_vectors[word] for word in words]\n",
    "\n",
    "# Reduce to 2D for visualization\n",
    "pca = PCA(n_components=2)\n",
    "reduced_vectors = pca.fit_transform(vectors)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i, word in enumerate(words):\n",
    "    plt.scatter(reduced_vectors[i, 0], reduced_vectors[i, 1], label=word)\n",
    "    plt.text(reduced_vectors[i, 0] + 0.02, reduced_vectors[i, 1], word, fontsize=12)\n",
    "plt.title(\"Word Embedding Visualization (King, Queen, Man, Woman)\")\n",
    "plt.xlabel(\"PCA Dimension 1\")\n",
    "plt.ylabel(\"PCA Dimension 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>yearbook_source</th>\n",
       "      <th>section</th>\n",
       "      <th>group</th>\n",
       "      <th>row_id</th>\n",
       "      <th>is_title</th>\n",
       "      <th>is_empty</th>\n",
       "      <th>original_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-1  Divisions of Administrative Areas in Chin...</td>\n",
       "      <td>2012</td>\n",
       "      <td>General Survey</td>\n",
       "      <td>B0101e</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPT...</td>\n",
       "      <td>2012</td>\n",
       "      <td>General Survey</td>\n",
       "      <td>B0101e</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(unit), EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMP...</td>\n",
       "      <td>2012</td>\n",
       "      <td>General Survey</td>\n",
       "      <td>B0101e</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>metadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPT...</td>\n",
       "      <td>2012</td>\n",
       "      <td>General Survey</td>\n",
       "      <td>B0101e</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Provinces  Autonomous , Number of, Cities, Num...</td>\n",
       "      <td>2012</td>\n",
       "      <td>General Survey</td>\n",
       "      <td>B0101e</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>header</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17398</th>\n",
       "      <td>United Kingdom, 0.66, 0.65, 0.78, 0.75, 0.78,...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Appendix II. A Comparison of Indicators of Eco...</td>\n",
       "      <td>E29-15</td>\n",
       "      <td>47</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>17398</td>\n",
       "      <td>table_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17399</th>\n",
       "      <td>Australia, 1.73, 1.09, 1.31, 1.34, 1.44, 1.45...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Appendix II. A Comparison of Indicators of Eco...</td>\n",
       "      <td>E29-15</td>\n",
       "      <td>48</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>17399</td>\n",
       "      <td>table_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17400</th>\n",
       "      <td>New Zealand, 2.2, 1.39, 1.41, 1.45, 1.52, 1.5...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Appendix II. A Comparison of Indicators of Eco...</td>\n",
       "      <td>E29-15</td>\n",
       "      <td>49</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>17400</td>\n",
       "      <td>table_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17401</th>\n",
       "      <td>EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPT...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Appendix II. A Comparison of Indicators of Eco...</td>\n",
       "      <td>E29-15</td>\n",
       "      <td>50</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>17401</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17402</th>\n",
       "      <td>EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPT...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Appendix II. A Comparison of Indicators of Eco...</td>\n",
       "      <td>E29-15</td>\n",
       "      <td>51</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>17402</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17403 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  yearbook_source  \\\n",
       "0      1-1  Divisions of Administrative Areas in Chin...             2012   \n",
       "1      EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPT...             2012   \n",
       "2      (unit), EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMP...             2012   \n",
       "3      EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPT...             2012   \n",
       "4      Provinces  Autonomous , Number of, Cities, Num...             2012   \n",
       "...                                                  ...              ...   \n",
       "17398   United Kingdom, 0.66, 0.65, 0.78, 0.75, 0.78,...             2022   \n",
       "17399   Australia, 1.73, 1.09, 1.31, 1.34, 1.44, 1.45...             2022   \n",
       "17400   New Zealand, 2.2, 1.39, 1.41, 1.45, 1.52, 1.5...             2022   \n",
       "17401  EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPT...             2022   \n",
       "17402  EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPT...             2022   \n",
       "\n",
       "                                                 section   group  row_id  \\\n",
       "0                                         General Survey  B0101e       1   \n",
       "1                                         General Survey  B0101e       2   \n",
       "2                                         General Survey  B0101e       3   \n",
       "3                                         General Survey  B0101e       4   \n",
       "4                                         General Survey  B0101e       5   \n",
       "...                                                  ...     ...     ...   \n",
       "17398  Appendix II. A Comparison of Indicators of Eco...  E29-15      47   \n",
       "17399  Appendix II. A Comparison of Indicators of Eco...  E29-15      48   \n",
       "17400  Appendix II. A Comparison of Indicators of Eco...  E29-15      49   \n",
       "17401  Appendix II. A Comparison of Indicators of Eco...  E29-15      50   \n",
       "17402  Appendix II. A Comparison of Indicators of Eco...  E29-15      51   \n",
       "\n",
       "      is_title is_empty  original_index       label  \n",
       "0          yes       no               0       title  \n",
       "1           no      yes               1       empty  \n",
       "2           no       no               2    metadata  \n",
       "3           no      yes               3       empty  \n",
       "4           no       no               4      header  \n",
       "...        ...      ...             ...         ...  \n",
       "17398       no       no           17398  table_data  \n",
       "17399       no       no           17399  table_data  \n",
       "17400       no       no           17400  table_data  \n",
       "17401       no      yes           17401       empty  \n",
       "17402       no      yes           17402       empty  \n",
       "\n",
       "[17403 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from project_config import TRAINING_DATA_FILE\n",
    "from utils.read_csv_file import read_csv_file\n",
    "\n",
    "df = read_csv_file(TRAINING_DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Final Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference file blank text cells: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - Detected encoding: ISO-8859-1 with confidence 0.73\n",
      "root - INFO - File read successfully from C:\\github\\table_lense\\pipeline_data\\training_inference\\training\\training_data_v1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_training file blank text cells: 0\n",
      "cleaned_training file blank text cells: 93\n",
      "combined file blank text cells: 93\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.read_csv_file import read_csv_file\n",
    "\n",
    "from project_config import (\n",
    "    INFERENCE_INPUT_DATA_FILE,\n",
    "    RAW_INFERENCE_OUTPUT_DATA_FILE,\n",
    "    CLEANED_INFERENCE_OUTPUT_DATA_FILE,\n",
    "    TRAINING_DATA_FILE,\n",
    "    CLEANED_TRAINING_OUTPUT_DATA_FILE,\n",
    "    COMBINED_CLEANED_OUTPUT_DATA_FILE,\n",
    ")\n",
    "\n",
    "df = pd.read_csv(CLEANED_INFERENCE_OUTPUT_DATA_FILE)\n",
    "blank_cells = df[\"text\"].isnull().sum()\n",
    "print(f\"inference file blank text cells: {blank_cells}\")\n",
    "\n",
    "df = read_csv_file(TRAINING_DATA_FILE)\n",
    "blank_cells = df[\"text\"].isnull().sum()\n",
    "print(f\"original_training file blank text cells: {blank_cells}\")\n",
    "\n",
    "df = pd.read_csv(CLEANED_TRAINING_OUTPUT_DATA_FILE)\n",
    "blank_cells = df[\"text\"].isnull().sum()\n",
    "print(f\"cleaned_training file blank text cells: {blank_cells}\")\n",
    "\n",
    "df = pd.read_csv(COMBINED_CLEANED_OUTPUT_DATA_FILE)\n",
    "blank_cells = df[\"text\"].isnull().sum()\n",
    "print(f\"combined file blank text cells: {blank_cells}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - Cleaning training data from: C:\\github\\table_lense\\pipeline_data\\training_inference\\training\\training_data_v1.csv\n",
      "data_processing.post_process_inference_data - INFO - Start processing file (C:\\github\\table_lense\\pipeline_data\\training_inference\\training\\training_data_v1.csv)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Retrieved username: xzhan\n",
      "[DEBUG] Log file path: C:\\github\\table_lense\\logs\\xzhan_20250322_172204.log\n",
      "[DEBUG] Logging successfully configured with a single file handler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data_processing.post_process_inference_data - INFO - Detected encoding: ISO-8859-1 with confidence 0.73\n",
      "data_processing.post_process_inference_data - INFO - File read successfully from C:\\github\\table_lense\\pipeline_data\\training_inference\\training\\training_data_v1.csv\n",
      "data_processing.post_process_inference_data - INFO - DataFrame loaded:\n",
      "                                                text  yearbook_source  \\\n",
      "0  1-1  Divisions of Administrative Areas in Chin...             2012   \n",
      "1  EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPT...             2012   \n",
      "2  (unit), EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMP...             2012   \n",
      "3  EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPTY, EMPT...             2012   \n",
      "4  Provinces  Autonomous , Number of, Cities, Num...             2012   \n",
      "\n",
      "          section   group  row_id is_title is_empty  original_index     label  \n",
      "0  General Survey  B0101e       1      yes       no               0     title  \n",
      "1  General Survey  B0101e       2       no      yes               1     empty  \n",
      "2  General Survey  B0101e       3       no       no               2  metadata  \n",
      "3  General Survey  B0101e       4       no      yes               3     empty  \n",
      "4  General Survey  B0101e       5       no       no               4    header  \n",
      "data_processing.post_process_inference_data - INFO - Predicted label column not found; skipping conversion.\n",
      "data_processing.post_process_inference_data - INFO - Renamed column 'label' to 'actual_label'.\n",
      "data_processing.post_process_inference_data - INFO - New column 'label' is created.\n",
      "data_processing.post_process_inference_data - INFO - Merged actual labels; final 'label' initialized from 'actual_label'.\n",
      "data_processing.post_process_inference_data - INFO - New column 'label_type' is created.\n",
      "data_processing.post_process_inference_data - INFO - Starting set_label_type function.\n",
      "data_processing.post_process_inference_data - INFO - Set 'label_type' to 'predicted' for unlabeled rows, else 'actual'.\n",
      "data_processing.post_process_inference_data - INFO - Completed set_label_type function.\n",
      "data_processing.post_process_inference_data - INFO - Starting merge_labels_based_on_type function.\n",
      "data_processing.post_process_inference_data - WARNING - Predicted label column 'predicted_label' not found; using actual labels for 'label'.\n",
      "data_processing.post_process_inference_data - INFO - Completed merge_labels_based_on_type function.\n",
      "data_processing.post_process_inference_data - INFO - DataFrame sorted.\n",
      "c:\\github\\table_lense\\src\\data_processing\\post_process_inference_data.py:377: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(clean_text)\n",
      "data_processing.post_process_inference_data - INFO - Text cleaned.\n",
      "data_processing.post_process_inference_data - INFO - Starting label_empty_rows function.\n",
      "data_processing.post_process_inference_data - INFO - Applied empty row labeling based on text content in 'text' column.\n",
      "data_processing.post_process_inference_data - INFO - Forced 'label' to 'empty' for rows where 'is_empty' equals 'yes'.\n",
      "data_processing.post_process_inference_data - INFO - Completed label_empty_rows function.\n",
      "data_processing.post_process_inference_data - INFO - Empty rows updated.\n",
      "data_processing.post_process_inference_data - INFO - Starting label_title function.\n",
      "data_processing.post_process_inference_data - INFO - Set 'label' to 'title' for rows where 'is_title' is 'yes'.\n",
      "data_processing.post_process_inference_data - INFO - Completed label_title function.\n",
      "data_processing.post_process_inference_data - INFO - Title rows updated.\n",
      "data_processing.post_process_inference_data - INFO - Metadata checked & reclassified.\n",
      "data_processing.post_process_inference_data - INFO - Reclassification of empty, metadata, and header rows completed.\n",
      "data_processing.post_process_inference_data - INFO - Cleaned data saved to C:\\github\\table_lense\\pipeline_data\\training_inference\\training\\cleaned_training_data.csv\n",
      "root - INFO - Cleaned training data saved to: C:\\github\\table_lense\\pipeline_data\\training_inference\\training\\cleaned_training_data.csv\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from data_processing.post_process_inference_data import (\n",
    "    process_inference_training_results,\n",
    ")\n",
    "from project_config import TRAINING_DATA_FILE, CLEANED_TRAINING_OUTPUT_DATA_FILE\n",
    "\n",
    "# Optional: Setup logging if you want to see output\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "\n",
    "def clean_training_data():\n",
    "    \"\"\"\n",
    "    Re-clean the training input data using the same cleaning pipeline\n",
    "    used in the inference pipeline.\n",
    "    \"\"\"\n",
    "    input_file = Path(TRAINING_DATA_FILE)\n",
    "    output_file = Path(CLEANED_TRAINING_OUTPUT_DATA_FILE)\n",
    "\n",
    "    logging.info(f\"Cleaning training data from: {input_file}\")\n",
    "    process_inference_training_results(\n",
    "        input_file_path=input_file, output_file_path=output_file\n",
    "    )\n",
    "    logging.info(f\"Cleaned training data saved to: {output_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_training_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
